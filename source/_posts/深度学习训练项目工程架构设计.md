---
title: 深度学习训练项目工程架构设计
tags:
  - 项目架构
  - 工程实践
  - PyTorch
  - Python
categories:
  - 深度学习
date: 2026-02-13 00:11:43
---

本文主要介绍了深度学习训练项目的通用工程架构：Core / Pipelines / Apps 三层分工，

并结合配置继承与命令行覆盖、uv 依赖管理和外部输出管理，提升项目的可维护性与实验可复现性。
<!-- more -->

## 1. 引言

你是否经历过这样的场景：

- 一个 `train.py` 文件写了 2000 行，模型定义、数据加载、训练循环、日志记录全部混在一起
- 想换个数据集或者换个 backbone，结果发现要改十几个地方
- 跑了几十个实验，checkpoint 和 log 散落各处，根本找不到哪个是哪个
- 想复用之前项目的代码，发现耦合太紧，只能复制粘贴再魔改

这些问题的根源在于：**缺乏合理的工程架构设计**。

本文介绍一种经过实践验证的三层架构设计：**Core → Pipelines → Apps**，帮助构建可复用、可扩展、易维护的深度学习训练项目。

## 2. 整体架构概览

### 三层设计

```
┌─────────────────────────────────────┐
│              Apps                   │  ← 入口层：参数解析、调用 Pipeline
├─────────────────────────────────────┤
│            Pipelines                │  ← 业务层：流程编排
├─────────────────────────────────────┤
│              Core                   │  ← 核心层：可复用组件
└─────────────────────────────────────┘
```

**依赖方向是单向的**：`Apps → Pipelines → Core`

这意味着：
- Core 层不依赖任何上层代码，可以独立测试和复用
- Pipelines 层只依赖 Core，不关心谁来调用它
- Apps 层是最薄的一层，只负责入口

### 各层职责

| 层级 | 职责 | 关键问题 |
|------|------|----------|
| Core | 提供可复用的"积木" | 我能做什么？（能力） |
| Pipelines | 把积木拼成完整流程 | 怎么做？（流程） |
| Apps | 入口，接收参数并触发流程 | 谁来触发？（入口） |

### 目录结构

```
project/
├── configs/                          # 配置文件
│   ├── _base_/                       # 基础配置（可继承）
│   │   ├── datasets/
│   │   ├── models/
│   │   └── schedules/
│   └── experiments/                  # 具体实验配置
│
├── core/                             # 领域核心（可复用、少依赖）
│   ├── modeling/
│   │   ├── backbones/
│   │   ├── heads/
│   │   ├── losses/
│   │   └── metrics/
│   ├── data/
│   │   ├── datasets/
│   │   ├── transforms/
│   │   ├── samplers/
│   │   └── builder.py
│   ├── engine/
│   │   ├── trainer.py
│   │   └── distributed.py
│   ├── eval/
│   │   └── evaluator.py
│   └── utils/
│       ├── registry.py
│       ├── config.py
│       ├── checkpoint.py
│       ├── logger.py
│       └── seed.py
│
├── pipelines/                        # 业务流程（编排积木）
│   ├── base.py                       # BasePipeline 抽象类
│   ├── supervised/                   # 示例：监督学习 baseline（可按需新增其他 pipeline）
│   └── README.md
│
├── apps/                             # 入口层
│   ├── train.py
│   ├── eval.py
│
│
├── tests/                            # 单元测试
├── scripts/                          # 运行脚本
├── pyproject.toml                    # 项目配置（uv）
└── README.md
```

## 3. Core 层：领域核心

Core 层是整个架构的基石，遵循一个核心原则：**不关心"实验是什么"，只提供积木**。

### core/modeling

modeling 模块负责所有与模型相关的组件：

- **backbones/**：存放特征提取网络，如 ResNet、ViT 等。只负责特征提取，不包含分类头
- **heads/**：分类头、投影头等。与 backbone 解耦，可以自由组合
- **losses/**：各种损失函数的实现，统一接口
- **metrics/**：评估指标的计算

#### 注册机制（Registry）

Registry 是让组件可配置化的关键。通过 `@BACKBONES.register("resnet50")` 这样的装饰器注册组件，然后在配置文件中通过 `type: resnet50` 指定，代码里一行 `BACKBONES.build(cfg)` 即可构建实例。

这样做的好处是：换模型只需改配置文件，不用改代码。

### core/data

数据模块负责数据加载的全流程：

- **datasets/**：数据集定义，只关心"如何读取一条数据"
- **transforms/**：数据增强的组合，区分训练和验证模式
- **samplers/**：采样器，支持分布式训练
- **builder.py**：统一的 DataLoader 构建入口，处理 batch、多进程、分布式等细节

### core/engine

engine 模块封装训练和验证的原子操作：

- **trainer.py**：`train_one_epoch()` 和 `validate()` 函数，处理混合精度、梯度累积、梯度裁剪等
- **distributed.py**：分布式训练的初始化和模型包装

这些函数是"无状态"的，接收模型、数据、优化器等参数，执行一个 epoch 的训练或验证，返回指标。Pipeline 层负责循环调用它们。

### core/eval

评测模块负责模型评估相关的逻辑：

- **evaluator.py**：累积预测结果，计算各种指标（accuracy、F1、混淆矩阵等）

### core/utils

工具函数集合：

- **registry.py**：注册机制实现
- **config.py**：配置加载，支持继承
- **checkpoint.py**：模型保存和加载
- **logger.py**：日志设置，支持控制台和文件输出
- **seed.py**：随机种子设置，保证可复现性

## 4. Pipelines 层：业务流程

Pipelines 层负责把 Core 的积木拼装成完整的训练流程。

### BasePipeline 抽象类

定义统一的接口：
- `build_model()`：构建模型
- `build_dataloader()`：构建数据加载器
- `build_optimizer()`：构建优化器和调度器
- `train()`：执行训练流程
- `evaluate()`：执行评估流程
- `run()`：主入口，依次调用上述方法

### Pipeline 的设计哲学

1. **Pipeline 负责"编排"，不负责"实现"**：具体的训练逻辑在 Core 层，Pipeline 只是按正确的顺序调用它们

2. **一个任务一个 Pipeline**：不同的任务（监督学习、自监督、半监督等）有不同的流程，放在不同的 Pipeline 里

3. **Pipeline 可以有多阶段**：比如先预训练再微调，或者迭代式训练，这些都是 Pipeline 的职责

## 5. Apps 层：入口与工具

Apps 层是最薄的一层，只负责：**解析参数 → 调用 Pipeline**。

- **apps/train.py**：训练入口。负责读取配置、合并命令行覆盖参数、初始化分布式、创建输出目录、初始化日志与随机种子，然后构建并运行 Pipeline（支持 `--resume` 断点续训）
- **apps/eval.py**：评估入口。负责读取配置、构建 Pipeline 并加载 checkpoint，再执行评估并打印指标

### 运行方式（uv）

项目依赖通过 `pyproject.toml` + uv 管理，并提供了脚本入口（`dl-train` / `dl-eval`）。

- 安装依赖：`uv sync`
- 训练：`uv run dl-train --config configs/experiments/example.yaml`
- 评估：`uv run dl-eval --config configs/experiments/example.yaml --checkpoint /path/to/epoch_9.pth`

如果你更习惯直接跑 Python 文件，也可以：

- 单卡：`python apps/train.py --config configs/experiments/example.yaml`
- 多卡：`torchrun --nproc_per_node=4 apps/train.py --config configs/experiments/example.yaml`

## 6. 配置管理

配置管理是实验可复现性的关键。

### 配置继承机制

借鉴 MMEngine 的设计，支持配置继承。把通用配置（模型、数据集、训练计划）放在 `_base_/` 目录，具体实验配置通过 `_base_:` 字段继承它们，然后覆盖特定配置。

好处是：
- 避免配置重复
- 修改基础配置自动影响所有继承它的实验
- 实验配置只包含差异部分，更清晰

### OmegaConf

使用 OmegaConf 库加载和合并配置，支持：
- YAML 格式
- 配置继承和合并
- 命令行参数覆盖（dotlist），例如：`python apps/train.py --config xxx.yaml optimizer.lr=0.001 train.amp=false`

在实现上通常会拆成两步：

- `load_config(path)`：读取 YAML，并递归处理 `_base_` 继承（相对路径以当前配置文件目录为基准）
- `merge_cli_args(cfg, opts)`：把命令行里额外的 `key=value` 覆盖项 merge 到 cfg

## 7. 实验产出管理

实验产出（checkpoint、log、以及可选的可视化产出如 TensorBoard 等）不应放在项目代码目录中，而是放到**外部指定目录**。

好处：
- 代码仓库保持干净，不会被大量实验文件污染
- 方便在不同机器上共享代码，输出路径按环境配置
- 实验数据可以放在大容量磁盘或 NAS 上

### 配置方式

两种方式指定输出根目录：
1. 配置文件：`output_root: /data/experiments`
2. 环境变量：`export EXP_OUTPUT_ROOT=/data/experiments`

实际执行时建议以环境变量为主（更适合多机器/多环境切换），配置文件作为默认值兜底：

- 优先级：`EXP_OUTPUT_ROOT` → `output_root` → `./outputs`
- 只有 rank 0 会创建输出目录和落盘文件，避免 DDP 多进程写冲突

### 输出目录结构

```
/data/experiments/
└── resnet50_cifar100_20260212_143052/ # 自动生成：实验名_时间戳
    ├── config.yaml                     # 完整配置备份
    ├── train.log                       # 训练日志
    ├── checkpoints/
    │   ├── epoch_0.pth
    │   └── best.pth
    └── tensorboard/                  # 可选：接入 TensorBoard 时产出
```

其中：

- `config.yaml` 是“最终生效的完整配置”（包含命令行覆盖后的结果），用于复现实验
- `checkpoints/epoch_k.pth` 保存 epoch、model、optimizer、scheduler 等状态
- `checkpoints/best.pth` 是当前最佳指标对应的权重快照

### 断点续训（Resume）

训练入口支持 `--resume /path/to/epoch_k.pth`：

- 会恢复 model/optimizer/scheduler
- 并从上次 epoch 的下一轮继续训练

建议在项目根目录创建软链接指向最近的实验，方便调试：
```bash
ln -sfn /data/experiments/resnet50_cifar100_20260212_143052 ./latest_exp
```

### 可复现性补充：DataLoader 级别的随机性

除了 `set_seed()` 设置全局随机种子外，DataLoader 侧也建议做两件事：

- 设置 `torch.Generator()`，确保 shuffle/采样的随机性可控
- 设置 `worker_init_fn`，确保多进程 worker 的 numpy/random 随机性可控

这样即使在多进程加载数据、随机数据增强较多的情况下，也能最大化保证实验可复现。

## 8. 总结

### 分层的核心收益

1. **复用性**：Core 层可以跨项目复用，换任务不用重写基础组件
2. **可维护性**：改一处不影响其他地方，bug 容易定位
3. **可测试性**：每一层都可以独立测试
4. **可扩展性**：新增任务只需新增 Pipeline，不动 Core
5. **团队协作**：不同人可以并行开发不同层

### 适用场景

这套架构特别适合：
- 需要跑大量实验的研究项目
- 多任务、多数据集的场景
- 多人协作的项目
- 需要长期维护和迭代的代码库

### 参考项目

如果想看真实的实现案例，可以参考：
- [MMEngine](https://github.com/open-mmlab/mmengine) — OpenMMLab 的训练框架
- [timm](https://github.com/huggingface/pytorch-image-models) — PyTorch Image Models
- [detectron2](https://github.com/facebookresearch/detectron2) — Facebook 的检测框架

这些项目都采用了类似的分层思想，值得学习借鉴。
